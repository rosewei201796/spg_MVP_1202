/**
 * Gemini AI æœåŠ¡ - ç”¨äºç”Ÿæˆå¤šæ ·åŒ–çš„å›¾ç‰‡æç¤ºè¯
 */

import { API_CONFIG } from './config';

/**
 * System prompt for Gemini 3 to generate diverse image-generation prompts
 * for a new Channel's cold start.
 */
export const SYSTEM_PROMPT = {
  "role": "system",
  "name": "cold_start_image_prompt_generator",
  "description": "A system prompt that generates diverse yet stylistically consistent image-generation prompts for a new Channel's cold start.",
  "objectives": [
    "Use ONLY user input prompt + uploaded theme images.",
    "Generate the first batch of image-generation prompts for a new Channel.",
    "Establish a coherent but diverse visual identity.",
    "You could reference on pre-defined style libraries. Do not limit to the style from user images.",
    "CRITICAL: If the uploaded image contains a character/person/IP, ALL generated prompts MUST maintain consistency with that character's identity, appearance, or have a realistic connection to them.",
    "CRITICAL: If user prompt mentions specific characters/persons/IPs, ALL generated prompts MUST center around these subjects."
  ],
  "tasks": {
    "1_extract_core_fields": {
      "description": "Automatically extract abstracted fields from user prompt + images.",
      "fields": {
        "X_core_theme": "Identify WHO/WHAT the channel is about. PRIORITY: If image contains a character/person/IP, describe their key visual features (appearance, clothing, distinctive traits). If user prompt mentions specific subjects, prioritize those. (Main subject, IP identity, visual motifs, worldbuilding hints.)",
        "Y_style_baseline": "Infer global style baseline from uploaded images. (Color palette, era, texture, lighting pattern, mood.)",
        "Z_variation_factors": [
          "At least 8 independent factors to create visual diversity.",
          "May include: composition, pose, lighting shifts, scene variation, emotional tone, color extensions, material/texture changes, fashion elements, surreal extensions."
        ]
      }
    },
    "2_weight_model": {
      "description": "Generate weights that guide prompt diversity.",
      "note": "Weights are used internally by the model. Do not show them to user unless asked.",
      "weights": {
        "composition": {
          "close_up": 0.2,
          "half_body": 0.4,
          "full_body": 0.4
        },
        "lighting": {
          "base_palette_extension": 0.4,
          "high_contrast": 0.3,
          "dramatic_spotlight": 0.2,
          "soft_diffuse": 0.1
        },
        "scene": {
          "primary_theme_scene": 0.6,
          "worldview_extension": 0.4
        },
        "emotion": {
          "user_prompt_primary_mood": 0.7,
          "contrastive_mood": 0.3
        },
        "texture_detail": {
          "high_detail_photographic": 0.7,
          "light_illustrative_touch": 0.2,
          "mild_surreal": 0.1
        }
      }
    },
    "3_prompt_template": {
      "description": "Template used to generate each final image prompt.",
      "template_string": "{X main subject}, in {scene derived from weight distribution}, rendered in {Y style baseline}, with variation: {Z_i}, featuring: high detail, defined lighting structure, clear composition, photographic lens language, suitable for high-quality image generation."
    },
    "4_output_requirements": {
      "format": "Model MUST output in the following structured format:",
      "schema": {
        "Cold Start Analysis": {
          "X_core_theme": "string",
          "Y_style_baseline": "string",
          "Z_variation_factors": ["string"]
        },
        "Weight Plan": {
          "composition": {
            "close_up": "float",
            "half_body": "float",
            "full_body": "float"
          },
          "lighting": {
            "base_palette_extension": "float",
            "high_contrast": "float",
            "dramatic_spotlight": "float",
            "soft_diffuse": "float"
          },
          "scene": {
            "primary_theme_scene": "float",
            "worldview_extension": "float"
          },
          "emotion": {
            "user_prompt_primary_mood": "float",
            "contrastive_mood": "float"
          },
          "texture_detail": {
            "high_detail_photographic": "float",
            "light_illustrative_touch": "float",
            "mild_surreal": "float"
          }
        },
        "Image Prompts": ["string"]
      }
    }
  },
  "generation_rules": [
    "All final outputs must be images only.",
    "All prompts must share the same X and Y.",
    "Each prompt must use a different Z_i.",
    "Ensure strong visual consistency across prompts.",
    "Ensure enough variety to fill the Channel's first feed.",
    "Suggested number of prompts: 8â€“12.",
    "CHARACTER CONSISTENCY RULE: If uploaded image shows a character/person/IP, every generated prompt MUST feature the SAME character with consistent appearance (face, body type, distinctive features, signature clothing/accessories).",
    "CHARACTER CONSISTENCY RULE: If user prompt specifies a character/person/IP name, every generated prompt MUST revolve around that specific subject.",
    "VARIATION SCOPE: Vary only the scene, pose, angle, lighting, emotion, and background - NEVER change the core character identity or their defining visual traits."
  ]
};

export interface GeminiPromptRequest {
  userPrompt: string;
  referenceImage?: string; // Base64 or URL (å¯é€‰)
  numPrompts?: number; // ç”Ÿæˆå¤šå°‘ä¸ªpromptsï¼Œé»˜è®¤8-12
}

export interface GeminiPromptResponse {
  success: boolean;
  analysis?: {
    X_core_theme: string;
    Y_style_baseline: string;
    Z_variation_factors: string[];
  };
  weightPlan?: any;
  prompts?: string[];
  error?: string;
}

/**
 * è°ƒç”¨ Gemini API ç”Ÿæˆå¤šæ ·åŒ–çš„å›¾ç‰‡æç¤ºè¯
 * ä½¿ç”¨ OpenAI å…¼å®¹æ¥å£è°ƒç”¨ vertex_ai/gemini-3-pro-preview
 */
export async function generateImagePromptsWithGemini(
  request: GeminiPromptRequest
): Promise<GeminiPromptResponse> {
  try {
    const apiKey = API_CONFIG.gemini.apiKey;
    const baseUrl = API_CONFIG.gemini.baseUrl;
    const model = API_CONFIG.gemini.promptModel;
    
    if (!apiKey) {
      console.warn('âš ï¸ Gemini API key not configured, using fallback');
      return generateFallbackPrompts(request);
    }

    console.log(`ğŸ§  Using model: ${model} for prompt generation`);

    // ç®€åŒ– system promptï¼Œé¿å…è¿‡äºå¤æ‚å¯¼è‡´æ¨¡å‹åªæ¨ç†ä¸è¾“å‡º
    const simpleSystemPrompt = `You are an expert at generating diverse image-generation prompts for AI image generation.

Your task: Generate ${request.numPrompts || 8} different image prompts based on the user's input.

Requirements:
- All prompts should share the same core subject/theme
- Each prompt should have different: composition, lighting, angle, mood, or scene
- Output ONLY a JSON array of strings
- Each string should be a detailed, complete image generation prompt

Output format (MUST be valid JSON):
{
  "prompts": [
    "detailed prompt 1...",
    "detailed prompt 2...",
    ...
  ]
}`;
    
    let userMessage = `User's idea: "${request.userPrompt}"`;
    
    if (request.referenceImage) {
      userMessage += `\n\nThe user has uploaded a reference image. Please analyze its style and generate prompts that match this style.`;
    }
    
    userMessage += `\n\nGenerate ${request.numPrompts || 8} diverse image prompts. Output as JSON with "prompts" array.`;

    // æ„å»ºæ¶ˆæ¯å†…å®¹ - æ”¯æŒå›¾ç‰‡è¾“å…¥
    const userContent: any = request.referenceImage 
      ? [
          { type: 'text', text: userMessage },
          { 
            type: 'image_url', 
            image_url: { 
              url: request.referenceImage,
              detail: 'high'
            } 
          }
        ]
      : userMessage;
    
    console.log('ğŸ“¤ Sending request with simplified prompt...');

    // ä½¿ç”¨ OpenAI å…¼å®¹æ¥å£è°ƒç”¨ vertex_ai Gemini æ¨¡å‹
    const response = await fetch(
      `${baseUrl}/chat/completions`,
      {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${apiKey}`,
        },
        body: JSON.stringify({
          model: model,
          messages: [
            {
              role: 'system',
              content: simpleSystemPrompt
            },
            {
              role: 'user',
              content: userContent
            }
          ],
          temperature: 0.8,
          max_tokens: 4096,
        }),
      }
    );

    if (!response.ok) {
      const error = await response.json();
      console.error('âŒ API returned error:', error);
      throw new Error(error.error?.message || `API error: ${response.status} ${response.statusText}`);
    }

    const data = await response.json();
    console.log('ğŸ“¦ Full API response:', JSON.stringify(data, null, 2));
    
    const generatedText = data.choices?.[0]?.message?.content || '';
    
    if (!generatedText) {
      console.error('âŒ No content in response. Full data:', data);
      throw new Error('API returned empty content. Check model compatibility and request format.');
    }

    console.log('ğŸ“ Gemini response received, length:', generatedText.length);

    // è§£æ Gemini çš„å“åº”
    const parsed = parseGeminiResponse(generatedText);
    
    if (!parsed.prompts || parsed.prompts.length === 0) {
      console.error('âŒ Failed to extract prompts from response');
      throw new Error('Could not extract prompts from Gemini response');
    }

    return {
      success: true,
      ...parsed,
    };
  } catch (error) {
    console.error('âŒ Gemini API error:', error);
    console.error('Error details:', error instanceof Error ? error.message : 'Unknown error');
    // å¦‚æœå¤±è´¥ï¼Œä½¿ç”¨fallback
    return generateFallbackPrompts(request);
  }
}

/**
 * è§£æ Gemini çš„ JSON å“åº”
 */
function parseGeminiResponse(text: string): Partial<GeminiPromptResponse> {
  try {
    console.log('ğŸ” Raw Gemini response:', text.substring(0, 200) + '...');
    
    // æ–¹æ³•1: å°è¯•æå– JSON ä»£ç å—ï¼ˆä½¿ç”¨æ›´å®½æ¾çš„åŒ¹é…ï¼‰
    const jsonBlockMatch = text.match(/```json\s*([\s\S]*?)\s*```/) || 
                          text.match(/```\s*([\s\S]*?)\s*```/);
    
    if (jsonBlockMatch) {
      const parsed = JSON.parse(jsonBlockMatch[1]);
      return {
        analysis: parsed['Cold Start Analysis'] || parsed['analysis'],
        weightPlan: parsed['Weight Plan'] || parsed['weightPlan'],
        prompts: parsed['Image Prompts'] || parsed['prompts'] || parsed['imagePrompts'],
      };
    }

    // æ–¹æ³•2: å°è¯•ç›´æ¥è§£æ JSONï¼ˆæŸ¥æ‰¾æœ€å¤–å±‚çš„å¤§æ‹¬å·ï¼‰
    const jsonMatch = text.match(/\{[\s\S]*\}/);
    if (jsonMatch) {
      // æ¸…ç†å¯èƒ½çš„æ ¼å¼é—®é¢˜
      let jsonStr = jsonMatch[0];
      // ç§»é™¤æ³¨é‡Š
      jsonStr = jsonStr.replace(/\/\*[\s\S]*?\*\//g, '');
      jsonStr = jsonStr.replace(/\/\/.*/g, '');
      
      const parsed = JSON.parse(jsonStr);
      return {
        analysis: parsed['Cold Start Analysis'] || parsed['analysis'],
        weightPlan: parsed['Weight Plan'] || parsed['weightPlan'],
        prompts: parsed['Image Prompts'] || parsed['prompts'] || parsed['imagePrompts'],
      };
    }

    // æ–¹æ³•3: å¦‚æœä»¥ä¸Šéƒ½å¤±è´¥ï¼Œå°è¯•æå–å¸¦å¼•å·çš„é•¿å­—ç¬¦ä¸²ä½œä¸º prompts
    const promptMatches = text.match(/"([^"]{30,})"/g);
    if (promptMatches && promptMatches.length > 0) {
      console.log(`ğŸ“ Extracted ${promptMatches.length} prompts from plain text`);
      return {
        prompts: promptMatches.map(p => p.replace(/"/g, '').trim()).filter(p => p.length > 20),
      };
    }

    throw new Error('Could not parse Gemini response - no valid JSON or prompts found');
  } catch (error) {
    console.error('âŒ Failed to parse Gemini response:', error);
    console.error('Response text:', text);
    return {};
  }
}

/**
 * Fallback: å½“ Gemini ä¸å¯ç”¨æ—¶ï¼ŒåŸºäºç”¨æˆ·promptç”Ÿæˆç®€å•çš„å˜åŒ–
 */
function generateFallbackPrompts(request: GeminiPromptRequest): GeminiPromptResponse {
  const basePrompt = request.userPrompt;
  const numPrompts = request.numPrompts || 8;

  // ä¸åŒçš„å˜åŒ–å› å­
  const variations = [
    'close-up portrait, dramatic lighting',
    'full body shot, natural outdoor setting',
    'half body view, studio lighting, professional photography',
    'dynamic action pose, motion blur effect',
    'serene mood, soft diffused lighting',
    'high contrast, cinematic composition',
    'aerial view, wide angle perspective',
    'detailed texture, macro photography style',
    'dramatic shadows, film noir aesthetic',
    'vibrant colors, sunset golden hour',
    'minimalist composition, clean background',
    'environmental portrait, contextual background',
  ];

  const prompts = variations.slice(0, numPrompts).map(variation => {
    return `${basePrompt}, ${variation}, high detail, photographic quality`;
  });

  return {
    success: true,
    analysis: {
      X_core_theme: basePrompt,
      Y_style_baseline: 'Photographic, high detail, professional quality',
      Z_variation_factors: variations.slice(0, numPrompts),
    },
    prompts,
  };
}

/**
 * ç”Ÿæˆçˆ†æ¬¾ Channel åå­—
 * æ ¹æ®ç”¨æˆ·çš„ prompt æ™ºèƒ½ç”Ÿæˆä¸€ä¸ªå¸å¼•äººçš„ channel åå­—
 */
export async function generateChannelName(
  userPrompt: string,
  referenceImage?: string
): Promise<{ success: boolean; name: string; error?: string }> {
  console.log('ğŸ·ï¸ [Channel Name] Generating from prompt:', userPrompt.substring(0, 60));

  // ä½¿ç”¨æ™ºèƒ½ç®—æ³•ç”Ÿæˆåå­—
  const name = generateSmartChannelName(userPrompt);
  
  console.log('âœ… [Channel Name] Generated:', name);
  return { success: true, name };
}

/**
 * æ™ºèƒ½ç”Ÿæˆ Channel åå­—ç®—æ³•
 * æå–å…³é”®è¯å¹¶ç»„åˆæˆå¸å¼•äººçš„æ ‡é¢˜
 */
function generateSmartChannelName(prompt: string): string {
  // å¸¸è§åœç”¨è¯
  const stopWords = new Set([
    'a', 'an', 'the', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for',
    'of', 'with', 'by', 'from', 'as', 'is', 'was', 'are', 'were', 'been',
    'be', 'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'should',
    'could', 'may', 'might', 'must', 'can', 'that', 'this', 'these', 'those',
  ]);

  // åˆ†è¯å¹¶æ¸…ç†
  const words = prompt
    .toLowerCase()
    .replace(/[^\w\s]/g, ' ') // ç§»é™¤æ ‡ç‚¹
    .split(/\s+/)
    .filter(word => word.length > 2 && !stopWords.has(word));

  // å¦‚æœæ²¡æœ‰æœ‰æ•ˆè¯ï¼Œè¿”å›é»˜è®¤åå­—
  if (words.length === 0) {
    return 'My Channel';
  }

  // é€‰å–æœ€é‡è¦çš„3-4ä¸ªè¯
  const selectedWords = words.slice(0, Math.min(4, words.length));

  // è½¬æ¢ä¸º Title Case
  const titleCase = selectedWords
    .map(word => {
      // ç‰¹æ®Šç¼©å†™ä¿æŒå¤§å†™
      if (['ai', 'vr', 'ar', '3d', '2d', 'nft'].includes(word)) {
        return word.toUpperCase();
      }
      return word.charAt(0).toUpperCase() + word.slice(1);
    })
    .join(' ');

  // ç¡®ä¿åå­—ä¸ä¼šå¤ªé•¿
  if (titleCase.length > 30) {
    const shorterWords = selectedWords.slice(0, 3);
    return shorterWords
      .map(word => word.charAt(0).toUpperCase() + word.slice(1))
      .join(' ');
  }

  return titleCase;
}

